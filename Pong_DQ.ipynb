{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pong_DQ.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abogaziah/Pong_DQN/blob/master/Pong_DQ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHcmYm4e2Rpg",
        "colab_type": "text"
      },
      "source": [
        "# Replay buffer\n",
        "Sotres a tuple of (State, action, reward, next state, termiante) every time step then samples it to the NN as a training set  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C29_rh5VJNj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import deque\n",
        "import random\n",
        "\n",
        "class buffer:\n",
        "\n",
        "  def __init__(self, buffer_size):\n",
        "    self.buffer_size = buffer_size\n",
        "    self.count=0\n",
        "    self.buffer=deque()\n",
        "\n",
        "  def append(self,s,a,r,s_,t):\n",
        "    step=(s,a,r,s_)\n",
        "    if self.count < self.buffer_size:\n",
        "      self.buffer.append(step)\n",
        "      self.count+=1\n",
        "    else:\n",
        "      self.buffer.popleft()\n",
        "      self.buffer.append(step)\n",
        "\n",
        "  def sample(self,batch_size):\n",
        "    batch=[]\n",
        "    if self.count <= batch_size:\n",
        "      batch=random.sample(self.buffer, self.count)\n",
        "    else:\n",
        "      batch=random.sample(self.buffer,batch_size)\n",
        "\n",
        "    s, a, r, s_ ,t = list(map(np.array, list(zip(*batch))))\n",
        "    return s, a, r, s_ , t\n",
        "\n",
        "  def clear(self):\n",
        "        self.buffer.clear()\n",
        "        self.count = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87d9q7G23SAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import gym\n",
        "import numpy as np\n",
        "import cv2\n",
        "from keras.models import load_model, Sequential\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers.core import Activation, Dropout, Flatten, Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-ryWo-4E17b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr=0.0001\n",
        "buffer_size=1000000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_vQ24-NFDDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dqn(n_actions,input_shape,lr):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(filters=32, kernel_size=8, strides=4, activation='relu',\n",
        "                    input_shape=(*input_shape,), data_format='channels_first'))\n",
        "  model.add(Conv2D(filters=64, kernel_size=4, strides=2, activation='relu',\n",
        "                    data_format='channels_first'))\n",
        "  model.add(Conv2D(filters=64, kernel_size=3, strides=1, activation='relu',\n",
        "                    data_format='channels_first'))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512, activation='relu'))\n",
        "  model.add(Dense(n_actions))\n",
        "\n",
        "  model.compile(optimizer=Adam(lr=lr), loss='mean_squared_error')\n",
        "\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHI4GJqfi-E_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class agent:\n",
        "  def __init__(self, alpha, gamma, n_actions, epsilon, batch_size, replace,\n",
        "                 input_dims, eps_dec=0.996,  eps_min=0.01,\n",
        "                 mem_size=1000000, q_eval='q_eval.h5',\n",
        "                 q_target='target.h5'):\n",
        "        self.action_space = [i for i in range(n_actions)]\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.eps_dec = eps_dec\n",
        "        self.eps_min = eps_min\n",
        "        self.batch_size = batch_size\n",
        "        self.replace = replace\n",
        "        self.q_target_model_file = q_target\n",
        "        self.q_eval_model_file = q_eval\n",
        "        self.learn_step = 0\n",
        "        self.memory = buffer(mem_size)\n",
        "        self.q_eval = build_dqn(alpha, n_actions, input_dims, 512)\n",
        "        self.q_next = build_dqn(alpha, n_actions, input_dims, 512)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}